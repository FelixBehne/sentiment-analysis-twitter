{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils import slang_dict, abbr_dict\n",
    "from fast_ml.utilities import reduce_memory_usage\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "# df = (\n",
    "#     pd.read_csv(\n",
    "#         \"../../data/02_intermediate/intermediate_tweets.csv\",\n",
    "#     )\n",
    "#     .replace(abbr_dict, regex=True)\n",
    "#     .replace(slang_dict, regex=True)\n",
    "#     .replace(\"'\", \"\")\n",
    "#     .replace(\"\\s+\", \" \", regex=True)\n",
    "#     .dropna()\n",
    "# )\n",
    "\n",
    "# # Reduce memory consumption\n",
    "# df = reduce_memory_usage(df, convert_to_category=False, verbose=False)\n",
    "\n",
    "# # Train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     df[\"text\"], df[\"target\"], test_size=0.33, random_state=42\n",
    "# )\n",
    "\n",
    "# # Instantiate tfidf vectorizer\n",
    "# tfidf_vectorizer = TfidfVectorizer(\n",
    "#     analyzer=\"word\", strip_accents=\"ascii\", stop_words=\"english\"\n",
    "# )\n",
    "\n",
    "# # Vectorize data\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# # Write data to disk\n",
    "# y_train.to_csv(\"../../data/05_model_input/y_train.csv\")\n",
    "# y_test.to_csv(\"../../data/05_model_input/y_test.csv\")\n",
    "# scipy.sparse.save_npz('../../data/05_model_input/X_train_tfidf.npz', X_train_tfidf)\n",
    "# scipy.sparse.save_npz('../../data/05_model_input/X_test_tfidf.npz', X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scipy.sparse.load_npz(\"../../data/05_model_input/X_train_tfidf.npz\")\n",
    "y_train = pd.read_csv(\"../../data/05_model_input/y_train.csv\")\n",
    "X_test = scipy.sparse.load_npz(\"../../data/05_model_input/X_test_tfidf.npz\")\n",
    "y_test = pd.read_csv(\"../../data/05_model_input/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76    262872\n",
      "           4       0.76      0.75      0.76    263816\n",
      "\n",
      "    accuracy                           0.76    526688\n",
      "   macro avg       0.76      0.76      0.76    526688\n",
      "weighted avg       0.76      0.76      0.76    526688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Vectorize test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, clf.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74    262872\n",
      "           4       0.74      0.73      0.74    263816\n",
      "\n",
      "    accuracy                           0.74    526688\n",
      "   macro avg       0.74      0.74      0.74    526688\n",
      "weighted avg       0.74      0.74      0.74    526688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SGDClassifier(\n",
    "    loss=\"hinge\", penalty=\"l2\", alpha=1e-3, random_state=42, max_iter=5, tol=None\n",
    ").fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, svm.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest  = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, random_forest.predict(X_test_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3f30943140f51c5cc4967d1da6a8fecec155e6e1dd18f27a3dab00d4fb24dc4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
